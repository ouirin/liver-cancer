{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import ntpath\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn import over_sampling\n",
    "from keras.utils import np_utils \n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy, categorical_crossentropy\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, AveragePooling2D, Concatenate, GlobalMaxPooling2D\n",
    "from keras.layers.advanced_activations import ReLU\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DROPOUT = False\n",
    "LEARN_RATE = 0.001\n",
    "Height = 128\n",
    "Weight = 128\n",
    "Channel= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################################################################################\n",
    "# #数据平衡处理\n",
    "# df_1 = df_train.loc[df_train[\"cancer_label\"]==1]\n",
    "# df_0 = df_train.loc[df_train[\"cancer_label\"]==0]\n",
    "# df_1_add1 = df_1.sample(379)\n",
    "# df_1_add2 = df_1.sample(378)\n",
    "# df_1 = pandas.concat([df_1,df_1_add1,df_1_add2])\n",
    "# df_train = pandas.concat([df_1,df_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "Full Count:  91564\n",
      "Orginal Grade_0:  18873\n",
      "Orginal Grade_1:  18462\n",
      "Orginal Grade_2:  12797\n",
      "Orginal Grade_3:  31434\n",
      "Orginal Grade_4:  9998\n",
      "Train Count Grade_0:  16985 , Holdout Count Grade_0:  1888\n",
      "Train Count Grade_1:  16615 , Holdout Count Grade_1:  1847\n",
      "Train Count Grade_2:  11517 , Holdout Count Grade_2:  1280\n",
      "Train Count Grade_3:  28290 , Holdout Count Grade_3:  3144\n",
      "Train Count Grade_4:  8998 , Holdout Count Grade_4:  1000\n",
      "Train Count:  82405 , Holdout Count:  9159\n",
      "Train Sample_X:  141450 , Train Sample_Y:  141450\n",
      "Train Count:  141450 , Holdout Count:  9159\n",
      "Train Count:  141450 , Holdout Count:  9159\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input (InputLayer)                     (None, 128, 128, 3)        0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1a (Conv2D)                        (None, 128, 128, 32)       896           input[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNormaliza (None, 128, 128, 32)       128           conv1a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                        (None, 128, 128, 32)       0             batch_normalization_32[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1b (Conv2D)                        (None, 128, 128, 32)       9248          re_lu_29[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNormaliza (None, 128, 128, 32)       128           conv1b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                        (None, 128, 128, 32)       0             batch_normalization_33[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)                   (None, 64, 64, 32)         0             re_lu_30[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePooling2D (None, 64, 64, 3)          0             input[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)           (None, 64, 64, 35)         0             pool1[0][0]                             \n",
      "                                                                                average_pooling2d_34[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "conv2a (Conv2D)                        (None, 64, 64, 64)         20224         concatenate_14[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNormaliza (None, 64, 64, 64)         256           conv2a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                        (None, 64, 64, 64)         0             batch_normalization_34[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv2b (Conv2D)                        (None, 64, 64, 64)         36928         re_lu_31[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNormaliza (None, 64, 64, 64)         256           conv2b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                        (None, 64, 64, 64)         0             batch_normalization_35[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)                   (None, 32, 32, 64)         0             re_lu_32[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePooling2D (None, 32, 32, 3)          0             average_pooling2d_34[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePooling2D (None, 32, 32, 35)         0             concatenate_14[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)           (None, 32, 32, 102)        0             pool2[0][0]                             \n",
      "                                                                                average_pooling2d_35[0][0]              \n",
      "                                                                                average_pooling2d_36[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "conv3a (Conv2D)                        (None, 32, 32, 128)        117632        concatenate_15[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNormaliza (None, 32, 32, 128)        512           conv3a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                        (None, 32, 32, 128)        0             batch_normalization_36[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv3b (Conv2D)                        (None, 32, 32, 128)        147584        re_lu_33[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNormaliza (None, 32, 32, 128)        512           conv3b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                        (None, 32, 32, 128)        0             batch_normalization_37[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)                   (None, 16, 16, 128)        0             re_lu_34[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_37 (AveragePooling2D (None, 16, 16, 3)          0             average_pooling2d_35[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_38 (AveragePooling2D (None, 16, 16, 35)         0             average_pooling2d_36[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_39 (AveragePooling2D (None, 16, 16, 102)        0             concatenate_15[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)           (None, 16, 16, 268)        0             pool3[0][0]                             \n",
      "                                                                                average_pooling2d_37[0][0]              \n",
      "                                                                                average_pooling2d_38[0][0]              \n",
      "                                                                                average_pooling2d_39[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "conv4a (Conv2D)                        (None, 16, 16, 256)        617728        concatenate_16[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNormaliza (None, 16, 16, 256)        1024          conv4a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                        (None, 16, 16, 256)        0             batch_normalization_38[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv4b (Conv2D)                        (None, 16, 16, 256)        590080        re_lu_35[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNormaliza (None, 16, 16, 256)        1024          conv4b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                        (None, 16, 16, 256)        0             batch_normalization_39[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)                   (None, 8, 8, 256)          0             re_lu_36[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_40 (AveragePooling2D (None, 8, 8, 3)            0             average_pooling2d_37[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_41 (AveragePooling2D (None, 8, 8, 35)           0             average_pooling2d_38[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_42 (AveragePooling2D (None, 8, 8, 102)          0             average_pooling2d_39[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_43 (AveragePooling2D (None, 8, 8, 268)          0             concatenate_16[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)           (None, 8, 8, 664)          0             pool4[0][0]                             \n",
      "                                                                                average_pooling2d_40[0][0]              \n",
      "                                                                                average_pooling2d_41[0][0]              \n",
      "                                                                                average_pooling2d_42[0][0]              \n",
      "                                                                                average_pooling2d_43[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalMaxPooli (None, 664)                0             concatenate_17[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNormaliza (None, 664)                2656          global_max_pooling2d_3[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_8 (Dense)                        (None, 64)                 42560         batch_normalization_40[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "out_class (Dense)                      (None, 5)                  325           dense_8[0][0]                           \n",
      "========================================================================================================================\n",
      "Total params: 1,589,701\n",
      "Trainable params: 1,586,453\n",
      "Non-trainable params: 3,248\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "learnrate:  0.001  epoch:  0\n",
      "10000/10000 [==============================] - 1375s 137ms/step - loss: 0.3839 - categorical_accuracy: 0.8569 - categorical_crossentropy: 0.3839 - val_loss: 0.7697 - val_categorical_accuracy: 0.7232 - val_categorical_crossentropy: 0.7697\n",
      "\n",
      "Epoch 00001: saving model to workdir/model_liver_CNN__e01-0.7697.hd5\n",
      "Epoch 2/10\n",
      "learnrate:  0.001  epoch:  1\n",
      "10000/10000 [==============================] - 1444s 144ms/step - loss: 0.2346 - categorical_accuracy: 0.9145 - categorical_crossentropy: 0.2346 - val_loss: 0.5253 - val_categorical_accuracy: 0.8111 - val_categorical_crossentropy: 0.5253\n",
      "\n",
      "Epoch 00002: saving model to workdir/model_liver_CNN__e02-0.5253.hd5\n",
      "Epoch 3/10\n",
      "learnrate:  0.001  epoch:  2\n",
      "10000/10000 [==============================] - 1421s 142ms/step - loss: 0.1812 - categorical_accuracy: 0.9339 - categorical_crossentropy: 0.1812 - val_loss: 0.7659 - val_categorical_accuracy: 0.7503 - val_categorical_crossentropy: 0.7659\n",
      "\n",
      "Epoch 00003: saving model to workdir/model_liver_CNN__e03-0.7659.hd5\n",
      "Epoch 4/10\n",
      "learnrate:  0.001  epoch:  3\n",
      "10000/10000 [==============================] - 1436s 144ms/step - loss: 0.1504 - categorical_accuracy: 0.9457 - categorical_crossentropy: 0.1504 - val_loss: 0.9283 - val_categorical_accuracy: 0.7175 - val_categorical_crossentropy: 0.9283\n",
      "\n",
      "Epoch 00004: saving model to workdir/model_liver_CNN__e04-0.9283.hd5\n",
      "Epoch 5/10\n",
      "learnrate:  0.001  epoch:  4\n",
      "10000/10000 [==============================] - 1439s 144ms/step - loss: 0.1285 - categorical_accuracy: 0.9531 - categorical_crossentropy: 0.1285 - val_loss: 0.9409 - val_categorical_accuracy: 0.7653 - val_categorical_crossentropy: 0.9409\n",
      "\n",
      "Epoch 00005: saving model to workdir/model_liver_CNN__e05-0.9409.hd5\n",
      "Epoch 6/10\n",
      "learnrate:  0.001  epoch:  5\n",
      " 7378/10000 [=====================>........] - ETA: 3:44 - loss: 0.1118 - categorical_accuracy: 0.9594 - categorical_crossentropy: 0.1118"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-23f18d82aa49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"liver_CNN\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_weights_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-166-91934d42e681>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model_name, load_weights_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#model.fit_generator(generator=train_gen, samples_per_epoch=len(train_files), nb_epoch=10, verbose=1, validation_data=holdout_gen, nb_val_samples=len(holdout_files), class_weight=\"auto\", callbacks=[checkpoint, learnrate_scheduler])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mholdout_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearnrate_scheduler\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"workdir/model_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_end.hd5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\my_keras\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\my_keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\my_keras\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\my_keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\my_keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\my_keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\my_keras\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAARM0lEQVR4nO3dfcyddX3H8ffHVtRNDUU6hm1ZiTYm1c2iDTRjmU4zKGyuaBiBRegYsyaCwYRson8Mh5poNnXiAwmOCmxOZENHNXVdw4hEI8iNMh4lNAijDdJqUVyMmrLv/ji/2rNyt9z9teec3rvfr+TKuc73evpeJ+T+cD02VYUkST2eM+kGJEmzlyEiSepmiEiSuhkikqRuhogkqdv8STcwbkcffXQtXbp00m1I0qxy5513/qCqFu5dn3MhsnTpUqampibdhiTNKkkena7u6SxJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlStzn3xPq+vPYvrpt0CyNx59+cd8DL/NflvzmCTibvuL+654CXOfkTJ4+gk8n7xju/ccDLfO13XzeCTibvdbd+7YCX+eQlXx5BJ5N30UfedMDLeCQiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKnbyEIkyZIktyS5P8l9SS5u9fcl2ZbkrjacPrTMe5JsSfJgklOH6qtbbUuSS4fqxye5vdW/kOSIUe2PJOmZRnkksgu4pKqWA6uAC5Msb9M+VlUr2rARoE07G3glsBr4dJJ5SeYBnwJOA5YD5wyt58NtXS8HngQuGOH+SJL2MrIQqarHq+rbbfwnwAPAov0ssga4vqp+XlXfA7YAJ7ZhS1U9XFW/AK4H1iQJ8AbgX9ry1wJnjGRnJEnTGss1kSRLgROA21vpoiR3J1mfZEGrLQIeG1psa6vtq/4S4EdVtWuv+nTbX5dkKsnUjh07DsUuSZIYQ4gkeSFwI/CuqnoKuBJ4GbACeBz4yKh7qKqrqmplVa1cuHDhqDcnSXPG/FGuPMlzGQTI56rqiwBV9cTQ9M8AX2lftwFLhhZf3Grso/5D4Mgk89vRyPD8kqQxGOXdWQGuBh6oqo8O1Y8dmu3NwL1tfANwdpLnJTkeWAZ8C7gDWNbuxDqCwcX3DVVVwC3AmW35tcBNo9ofSdIzjfJI5GTgXOCeJHe12nsZ3F21AijgEeDtAFV1X5IbgPsZ3Nl1YVU9DZDkImATMA9YX1X3tfW9G7g+yQeA7zAILUnSmIwsRKrq60CmmbRxP8t8EPjgNPWN0y1XVQ8zuHtLkjQBPrEuSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuIwuRJEuS3JLk/iT3Jbm41Y9KsjnJQ+1zQasnyRVJtiS5O8lrhta1ts3/UJK1Q/XXJrmnLXNFkoxqfyRJzzTKI5FdwCVVtRxYBVyYZDlwKXBzVS0Dbm7fAU4DlrVhHXAlDEIHuAw4CTgRuGx38LR53ja03OoR7o8kaS8jC5Gqeryqvt3GfwI8ACwC1gDXttmuBc5o42uA62rgNuDIJMcCpwKbq2pnVT0JbAZWt2kvrqrbqqqA64bWJUkag7FcE0myFDgBuB04pqoeb5O+DxzTxhcBjw0ttrXV9lffOk19uu2vSzKVZGrHjh0HtzOSpF8aeYgkeSFwI/CuqnpqeFo7gqhR91BVV1XVyqpauXDhwlFvTpLmjJGGSJLnMgiQz1XVF1v5iXYqiva5vdW3AUuGFl/cavurL56mLkkak1HenRXgauCBqvro0KQNwO47rNYCNw3Vz2t3aa0CftxOe20CTkmyoF1QPwXY1KY9lWRV29Z5Q+uSJI3B/BGu+2TgXOCeJHe12nuBDwE3JLkAeBQ4q03bCJwObAF+CpwPUFU7k7wfuKPNd3lV7Wzj7wCuAV4AfLUNkqQxGVmIVNXXgX09t/HGaeYv4MJ9rGs9sH6a+hTwqoNoU5J0EHxiXZLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktRtRiGS5OaZ1CRJc8v8/U1M8nzgV4CjkywA0ia9GFg04t4kSYe5/YYI8HbgXcBLgTvZEyJPAZ8cXVuSpNlgvyFSVR8HPp7knVX1iTH1JEmaJZ7tSASAqvpEkt8Glg4vU1XXjagvSdIsMKMQSfIPwMuAu4CnW7kAQ0SS5rAZhQiwElheVTXKZiRJs8tMnxO5F/j1A1lxkvVJtie5d6j2viTbktzVhtOHpr0nyZYkDyY5dai+utW2JLl0qH58kttb/QtJjjiQ/iRJB2+mIXI0cH+STUk27B6eZZlrgNXT1D9WVSvasBEgyXLgbOCVbZlPJ5mXZB7wKeA0YDlwTpsX4MNtXS8HngQumOG+SJIOkZmeznrfga64qm5NsnSGs68Brq+qnwPfS7IFOLFN21JVDwMkuR5Yk+QB4A3An7R5rm09XnmgfUqS+s307qyvHcJtXpTkPGAKuKSqnmTw4OJtQ/NsZc/DjI/tVT8JeAnwo6raNc38z5BkHbAO4LjjjjsU+yBJYuavPflJkqfa8LMkTyd5qmN7VzK4y2sF8DjwkY51HLCquqqqVlbVyoULF45jk5I0J8z0SORFu8eThMHpp1UHurGqemJoPZ8BvtK+bgOWDM26uNXYR/2HwJFJ5rejkeH5JUljcsBv8a2BfwVOfbZ595bk2KGvb2Zw1xfABuDsJM9LcjywDPgWcAewrN2JdQSDi+8b2q3GtwBntuXXAjcdaD+SpIMz04cN3zL09TkMnhv52bMs83ng9Qxe3rgVuAx4fZIVDB5UfITBu7moqvuS3ADcD+wCLqyqp9t6LgI2AfOA9VV1X9vEu4Hrk3wA+A5w9Uz2RZJ06Mz07qw3DY3vYhAAa/a3QFWdM015n3/oq+qDwAenqW8ENk5Tf5g9d3BJkiZgptdEzh91I5Kk2Wemd2ctTvKl9gT69iQ3Jlk86uYkSYe3mV5Y/yyDi98vbcOXW02SNIfNNEQWVtVnq2pXG64BfOBCkua4mYbID5O8dff7rJK8lcGzGpKkOWymIfJnwFnA9xk8aX4m8Kcj6kmSNEvM9Bbfy4G17T1XJDkK+FsG4SJJmqNmeiTyW7sDBKCqdgInjKYlSdJsMdMQeU6SBbu/tCORmR7FSJL+n5ppEHwE+GaSf27f/5hpni6XJM0tM31i/bokUwz+ISiAt1TV/aNrS5I0G8z4lFQLDYNDkvRLB/wqeEmSdjNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUreRhUiS9Um2J7l3qHZUks1JHmqfC1o9Sa5IsiXJ3UleM7TM2jb/Q0nWDtVfm+SetswVSTKqfZEkTW+URyLXAKv3ql0K3FxVy4Cb23eA04BlbVgHXAm//LfcLwNOAk4ELhv6t96vBN42tNze25IkjdjIQqSqbgV27lVeA1zbxq8FzhiqX1cDtwFHJjkWOBXYXFU7q+pJYDOwuk17cVXdVlUFXDe0LknSmIz7msgxVfV4G/8+cEwbXwQ8NjTf1lbbX33rNHVJ0hhN7MJ6O4KocWwrybokU0mmduzYMY5NStKcMO4QeaKdiqJ9bm/1bcCSofkWt9r+6ounqU+rqq6qqpVVtXLhwoUHvROSpIFxh8gGYPcdVmuBm4bq57W7tFYBP26nvTYBpyRZ0C6onwJsatOeSrKq3ZV13tC6JEljMn9UK07yeeD1wNFJtjK4y+pDwA1JLgAeBc5qs28ETge2AD8Fzgeoqp1J3g/c0ea7vKp2X6x/B4M7wF4AfLUNkqQxGlmIVNU5+5j0xmnmLeDCfaxnPbB+mvoU8KqD6VGSdHB8Yl2S1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt4mESJJHktyT5K4kU612VJLNSR5qnwtaPUmuSLIlyd1JXjO0nrVt/oeSrJ3EvkjSXDbJI5Hfq6oVVbWyfb8UuLmqlgE3t+8ApwHL2rAOuBIGoQNcBpwEnAhctjt4JEnjcTidzloDXNvGrwXOGKpfVwO3AUcmORY4FdhcVTur6klgM7B6zD1L0pw2qRAp4N+T3JlkXasdU1WPt/HvA8e08UXAY0PLbm21fdWfIcm6JFNJpnbs2HGo9kGS5rz5E9ru71TVtiS/BmxO8t3hiVVVSepQbayqrgKuAli5cuUhW68kzXUTORKpqm3tczvwJQbXNJ5op6lon9vb7NuAJUOLL261fdUlSWMy9hBJ8qtJXrR7HDgFuBfYAOy+w2otcFMb3wCc1+7SWgX8uJ322gSckmRBu6B+SqtJksZkEqezjgG+lGT39v+pqv4tyR3ADUkuAB4FzmrzbwROB7YAPwXOB6iqnUneD9zR5ru8qnaObzckSWMPkap6GHj1NPUfAm+cpl7AhftY13pg/aHuUZI0M4fTLb6SpFnGEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUrdZHyJJVid5MMmWJJdOuh9JmktmdYgkmQd8CjgNWA6ck2T5ZLuSpLljVocIcCKwpaoerqpfANcDaybckyTNGamqSffQLcmZwOqq+vP2/VzgpKq6aK/51gHr2tdXAA+OtdFnOhr4wYR7OFz4W+zhb7GHv8Ueh8tv8RtVtXDv4vxJdDJuVXUVcNWk+9gtyVRVrZx0H4cDf4s9/C328LfY43D/LWb76axtwJKh74tbTZI0BrM9RO4AliU5PskRwNnAhgn3JElzxqw+nVVVu5JcBGwC5gHrq+q+Cbc1E4fNqbXDgL/FHv4We/hb7HFY/xaz+sK6JGmyZvvpLEnSBBkikqRuhsiY+ZqWgSTrk2xPcu+ke5m0JEuS3JLk/iT3Jbl40j1NSpLnJ/lWkv9sv8VfT7qnSUoyL8l3knxl0r3siyEyRr6m5f+4Blg96SYOE7uAS6pqObAKuHAO/3fxc+ANVfVqYAWwOsmqybY0URcDD0y6if0xRMbL17Q0VXUrsHPSfRwOqurxqvp2G/8Jgz8aiybb1WTUwH+3r89tw5y8+yfJYuAPgL+fdC/7Y4iM1yLgsaHvW5mjfyw0vSRLgROA2yfcysS0Uzh3AduBzVU1V3+LvwP+EvifCfexX4aIdJhI8kLgRuBdVfXUpPuZlKp6uqpWMHgDxYlJXjXhlsYuyR8C26vqzkn38mwMkfHyNS2aVpLnMgiQz1XVFyfdz+Ggqn4E3MLcvHZ2MvBHSR5hcNr7DUn+cbItTc8QGS9f06JnSBLgauCBqvropPuZpCQLkxzZxl8A/D7w3Yk2NQFV9Z6qWlxVSxn8nfiPqnrrhNualiEyRlW1C9j9mpYHgBtmyWtaDrkknwe+CbwiydYkF0y6pwk6GTiXwf9t3tWG0yfd1IQcC9yS5G4G/9O1uaoO29tb5WtPJEkHwSMRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdftffVKvAV5/iGIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    if True:\n",
    "            \n",
    "        train(model_name=\"liver_CNN\", load_weights_path=None)      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, load_weights_path):\n",
    "    \n",
    "    batch_size = 16\n",
    "\n",
    "    #获得训练和测试集合，以：路径、class label的形式保存\n",
    "    train_files, holdout_files = get_train_holdout_files(train_percentage=90)\n",
    "\n",
    "    #训练数据集\n",
    "    train_gen = data_generator(batch_size, train_files, train_set=True)\n",
    "\n",
    "    #测试数据集\n",
    "    holdout_gen = data_generator(batch_size, holdout_files, train_set=False)\n",
    "\n",
    "    #动态设置学习率\n",
    "    learnrate_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "    #获取model\n",
    "    model = get_net(load_weight_path=load_weights_path)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\"workdir/model_\" + model_name + \"_\"  + \"_e\" + \"{epoch:02d}-{val_loss:.4f}.hd5\", monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    #model.fit_generator(generator=train_gen, samples_per_epoch=len(train_files), nb_epoch=10, verbose=1, validation_data=holdout_gen, nb_val_samples=len(holdout_files), class_weight=\"auto\", callbacks=[checkpoint, learnrate_scheduler])\n",
    "    model.fit_generator(generator=train_gen, samples_per_epoch=10000, nb_epoch=10, verbose=1, validation_data=holdout_gen, nb_val_samples=len(holdout_files), class_weight=\"auto\", callbacks=[checkpoint, learnrate_scheduler])\n",
    "\n",
    "    model.save(\"workdir/model_\" + model_name + \"_end.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    res = 0.001\n",
    "    if epoch > 100:\n",
    "        res = 0.0001\n",
    "    print(\"learnrate: \", res, \" epoch: \", epoch)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(input_shape=(Height, Weight, Channel), load_weight_path=None) -> Model:  #期待返回类型为model\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name=\"input\")\n",
    "    x = inputs\n",
    "    \n",
    "    ##################################################################################################################\n",
    "    x_ident_1 = x\n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    # 1st layer group\n",
    "    x = Convolution2D(16, 3, 3, activation=None, border_mode='same', name='conv1a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(16, 3, 3, activation=None, border_mode='same', name='conv1b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool1')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1])\n",
    "    \n",
    "    ##################################################################################################################\n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 2nd layer group\n",
    "    x = Convolution2D(32, 3, 3, activation=None, border_mode='same', name='conv2a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(32, 3, 3, activation=None, border_mode='same', name='conv2b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool2')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2])\n",
    "\n",
    "    ##################################################################################################################\n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_2)\n",
    "    x_ident_3 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 3rd layer group\n",
    "    x = Convolution2D(64, 3, 3, activation=None, border_mode='same', name='conv3a', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(64, 3, 3, activation=None, border_mode='same', name='conv3b', subsample=(1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool3')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2,x_ident_3])\n",
    "     \n",
    "    ##################################################################################################################\n",
    "    x_ident_1 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_1)\n",
    "    x_ident_2 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_2)\n",
    "    x_ident_3 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x_ident_3)\n",
    "    x_ident_4 = AveragePooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid')(x)\n",
    "    # 4th layer group\n",
    "    x = Convolution2D(128, 3, 3, activation=None, border_mode='same', name='conv4a', subsample=(1, 1),)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Convolution2D(128, 3, 3, activation=None, border_mode='same', name='conv4b', subsample=(1, 1),)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='valid', name='pool4')(x)\n",
    "    x = Concatenate(axis=3)([x,x_ident_1,x_ident_2,x_ident_3,x_ident_4])\n",
    "    \n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = BatchNormalization(name=\"final_features\")(x)\n",
    "    \n",
    "    ##################################################################################################################\n",
    "    if USE_DROPOUT:\n",
    "        x = Dropout(p=0.3)(x)\n",
    "        \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    out_class = Dense(5, activation='softmax', name='out_class')(x)\n",
    "\n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    \n",
    "    if load_weight_path is not None:\n",
    "        model.load_weights(load_weight_path, by_name=False)\n",
    "\n",
    "    #编译模型\n",
    "    model.compile(optimizer=SGD(lr=LEARN_RATE, momentum=0.9, nesterov=True), loss={ \"out_class\": \"categorical_crossentropy\" }, metrics={\"out_class\": [categorical_accuracy, categorical_crossentropy] } )\n",
    "    model.summary(line_length=120)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input (InputLayer)                     (None, 128, 128, 3)        0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1a (Conv2D)                        (None, 128, 128, 16)       448           input[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNormaliza (None, 128, 128, 16)       64            conv1a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                        (None, 128, 128, 16)       0             batch_normalization_41[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1b (Conv2D)                        (None, 128, 128, 16)       2320          re_lu_37[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNormaliza (None, 128, 128, 16)       64            conv1b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                        (None, 128, 128, 16)       0             batch_normalization_42[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)                   (None, 64, 64, 16)         0             re_lu_38[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_44 (AveragePooling2D (None, 64, 64, 3)          0             input[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)           (None, 64, 64, 19)         0             pool1[0][0]                             \n",
      "                                                                                average_pooling2d_44[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "conv2a (Conv2D)                        (None, 64, 64, 32)         5504          concatenate_18[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNormaliza (None, 64, 64, 32)         128           conv2a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                        (None, 64, 64, 32)         0             batch_normalization_43[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv2b (Conv2D)                        (None, 64, 64, 32)         9248          re_lu_39[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNormaliza (None, 64, 64, 32)         128           conv2b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                        (None, 64, 64, 32)         0             batch_normalization_44[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)                   (None, 32, 32, 32)         0             re_lu_40[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_45 (AveragePooling2D (None, 32, 32, 3)          0             average_pooling2d_44[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_46 (AveragePooling2D (None, 32, 32, 19)         0             concatenate_18[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)           (None, 32, 32, 54)         0             pool2[0][0]                             \n",
      "                                                                                average_pooling2d_45[0][0]              \n",
      "                                                                                average_pooling2d_46[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "conv3a (Conv2D)                        (None, 32, 32, 64)         31168         concatenate_19[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNormaliza (None, 32, 32, 64)         256           conv3a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                        (None, 32, 32, 64)         0             batch_normalization_45[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv3b (Conv2D)                        (None, 32, 32, 64)         36928         re_lu_41[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNormaliza (None, 32, 32, 64)         256           conv3b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                        (None, 32, 32, 64)         0             batch_normalization_46[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)                   (None, 16, 16, 64)         0             re_lu_42[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_47 (AveragePooling2D (None, 16, 16, 3)          0             average_pooling2d_45[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_48 (AveragePooling2D (None, 16, 16, 19)         0             average_pooling2d_46[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_49 (AveragePooling2D (None, 16, 16, 54)         0             concatenate_19[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)           (None, 16, 16, 140)        0             pool3[0][0]                             \n",
      "                                                                                average_pooling2d_47[0][0]              \n",
      "                                                                                average_pooling2d_48[0][0]              \n",
      "                                                                                average_pooling2d_49[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "conv4a (Conv2D)                        (None, 16, 16, 128)        161408        concatenate_20[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNormaliza (None, 16, 16, 128)        512           conv4a[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                        (None, 16, 16, 128)        0             batch_normalization_47[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv4b (Conv2D)                        (None, 16, 16, 128)        147584        re_lu_43[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNormaliza (None, 16, 16, 128)        512           conv4b[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                        (None, 16, 16, 128)        0             batch_normalization_48[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)                   (None, 8, 8, 128)          0             re_lu_44[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_50 (AveragePooling2D (None, 8, 8, 3)            0             average_pooling2d_47[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_51 (AveragePooling2D (None, 8, 8, 19)           0             average_pooling2d_48[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_52 (AveragePooling2D (None, 8, 8, 54)           0             average_pooling2d_49[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "average_pooling2d_53 (AveragePooling2D (None, 8, 8, 140)          0             concatenate_20[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)           (None, 8, 8, 344)          0             pool4[0][0]                             \n",
      "                                                                                average_pooling2d_50[0][0]              \n",
      "                                                                                average_pooling2d_51[0][0]              \n",
      "                                                                                average_pooling2d_52[0][0]              \n",
      "                                                                                average_pooling2d_53[0][0]              \n",
      "________________________________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalMaxPooli (None, 344)                0             concatenate_21[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNormaliza (None, 344)                1376          global_max_pooling2d_4[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_9 (Dense)                        (None, 64)                 22080         batch_normalization_49[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "out_class (Dense)                      (None, 5)                  325           dense_9[0][0]                           \n",
      "========================================================================================================================\n",
      "Total params: 420,309\n",
      "Trainable params: 418,661\n",
      "Non-trainable params: 1,648\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x13ba09e2a58>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, record_list, train_set):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        batch_index = 0\n",
    "        image_list = []\n",
    "        label_list = []\n",
    "\n",
    "        if train_set:\n",
    "            random.shuffle(record_list)\n",
    "\n",
    "        #逐一遍历所有数据\n",
    "        for index, record_item in enumerate(record_list):\n",
    "\n",
    "            sample_path = record_item[0]\n",
    "            sample_label = record_item[1]\n",
    "\n",
    "            #转换成多分类标签\n",
    "            sample_label = np_utils.to_categorical(sample_label,5)  \n",
    "\n",
    "            #读取图片、修改尺寸、标准化\n",
    "            sample_image = cv2.imread(sample_path)\n",
    "            sample_image = (sample_image - np.average(sample_image)) / np.std(sample_image)\n",
    "            sample_image = sample_image.reshape(1, sample_image.shape[0], sample_image.shape[1], 3)\n",
    "\n",
    "            #数据增强\n",
    "            if train_set:  \n",
    "                if random.randint(0, 100) > 50:\n",
    "                    sample_image = np.fliplr(sample_image)\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    sample_image = np.flipud(sample_image)\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    sample_image = sample_image[:,::-1]\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    sample_image = sample_image[::-1, :]\n",
    "\n",
    "            #添加数据\n",
    "            image_list.append(sample_image)\n",
    "            label_list.append(sample_label)\n",
    "            batch_index += 1\n",
    "\n",
    "            if batch_index >= batch_size:\n",
    "                x = np.vstack(image_list)\n",
    "                y = np.vstack(label_list)\n",
    "                yield x, y\n",
    "                image_list = []\n",
    "                label_list = []\n",
    "                batch_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_holdout_files(train_percentage=90):\n",
    "    \n",
    "    print(\"Get train/holdout files.\")\n",
    "        \n",
    "    src_dir = \"D:/jupyter-notebook/LiverCancer/Image_Nuclei/images/\"\n",
    "    file_paths = []\n",
    "\n",
    "    for fold_1 in os.listdir(src_dir):\n",
    "\n",
    "        for fold_2 in os.listdir(src_dir+fold_1+\"/\"):\n",
    "\n",
    "            file_paths = file_paths + [file_path for file_path in glob.glob(src_dir+fold_1+\"/\"+fold_2+\"/*.jpg\")]\n",
    "        \n",
    "    print(\"Full Count: \",len(file_paths))\n",
    "    \n",
    "    #####################################################################################\n",
    "    samples_grade_0 = []\n",
    "    samples_grade_1 = []\n",
    "    samples_grade_2 = []\n",
    "    samples_grade_3 = []\n",
    "    samples_grade_4 = []\n",
    "    \n",
    "    for index, sample_path in enumerate(file_paths):\n",
    "        \n",
    "        if \"grade0\" in sample_path:\n",
    "            samples_grade_0 += [ [sample_path, 0] ]\n",
    "        elif \"grade1\" in sample_path:\n",
    "            samples_grade_1 += [ [sample_path, 1] ]\n",
    "        elif \"grade2\" in sample_path:\n",
    "            samples_grade_2 += [ [sample_path, 2] ]\n",
    "        elif \"grade3\" in sample_path:\n",
    "            samples_grade_3 += [ [sample_path, 3] ]\n",
    "        elif \"grade4\" in sample_path:\n",
    "            samples_grade_4 += [ [sample_path, 4] ]\n",
    "        \n",
    "    print(\"Orginal Grade_0: \", len(samples_grade_0))\n",
    "    print(\"Orginal Grade_1: \", len(samples_grade_1))\n",
    "    print(\"Orginal Grade_2: \", len(samples_grade_2))\n",
    "    print(\"Orginal Grade_3: \", len(samples_grade_3))\n",
    "    print(\"Orginal Grade_4: \", len(samples_grade_4))\n",
    "    \n",
    "    #####################################################################################\n",
    "    #分割训练数据和测试数据\n",
    "    train_count_grade_0 = int((len(samples_grade_0) * train_percentage) / 100)\n",
    "    train_count_grade_1 = int((len(samples_grade_1) * train_percentage) / 100)\n",
    "    train_count_grade_2 = int((len(samples_grade_2) * train_percentage) / 100)\n",
    "    train_count_grade_3 = int((len(samples_grade_3) * train_percentage) / 100)\n",
    "    train_count_grade_4 = int((len(samples_grade_4) * train_percentage) / 100)\n",
    "    train_samples_grade_0 = samples_grade_0[:train_count_grade_0]\n",
    "    train_samples_grade_1 = samples_grade_1[:train_count_grade_1]\n",
    "    train_samples_grade_2 = samples_grade_2[:train_count_grade_2]\n",
    "    train_samples_grade_3 = samples_grade_3[:train_count_grade_3]\n",
    "    train_samples_grade_4 = samples_grade_4[:train_count_grade_4]\n",
    "    holdout_samples_grade_0 = samples_grade_0[train_count_grade_0:]\n",
    "    holdout_samples_grade_1 = samples_grade_1[train_count_grade_1:]\n",
    "    holdout_samples_grade_2 = samples_grade_2[train_count_grade_2:]\n",
    "    holdout_samples_grade_3 = samples_grade_3[train_count_grade_3:]\n",
    "    holdout_samples_grade_4 = samples_grade_4[train_count_grade_4:]\n",
    "    \n",
    "    print(\"Train Count Grade_0: \", len(train_samples_grade_0), \", Holdout Count Grade_0: \", len(holdout_samples_grade_0))\n",
    "    print(\"Train Count Grade_1: \", len(train_samples_grade_1), \", Holdout Count Grade_1: \", len(holdout_samples_grade_1))\n",
    "    print(\"Train Count Grade_2: \", len(train_samples_grade_2), \", Holdout Count Grade_2: \", len(holdout_samples_grade_2))\n",
    "    print(\"Train Count Grade_3: \", len(train_samples_grade_3), \", Holdout Count Grade_3: \", len(holdout_samples_grade_3))\n",
    "    print(\"Train Count Grade_4: \", len(train_samples_grade_4), \", Holdout Count Grade_4: \", len(holdout_samples_grade_4))\n",
    "    \n",
    "    train_samples = train_samples_grade_0 + train_samples_grade_1 + train_samples_grade_2 + train_samples_grade_3 + train_samples_grade_4\n",
    "    holdout_samples = holdout_samples_grade_0 + holdout_samples_grade_1 + holdout_samples_grade_2 + holdout_samples_grade_3 + holdout_samples_grade_4\n",
    "    print(\"Train Count: \", len(train_samples), \", Holdout Count: \", len(holdout_samples))\n",
    "    \n",
    "    #####################################################################################\n",
    "    #训练集数据平衡\n",
    "    train_samples_x = np.array(train_samples)[:,0].reshape(-1,1)\n",
    "    train_samples_y = np.array(train_samples)[:,1].reshape(-1,1)\n",
    "                                                           \n",
    "    ros = over_sampling.RandomOverSampler(random_state=0)\n",
    "    train_samples_x, train_samples_y = ros.fit_sample(train_samples_x, train_samples_y)\n",
    "    print(\"Train Sample_X: \", len(train_samples_x), \", Train Sample_Y: \", len(train_samples_y))\n",
    "    \n",
    "    sns.countplot(train_samples_y)\n",
    "    \n",
    "    train_samples_x = train_samples_x.reshape(-1,1)\n",
    "    train_samples_y = train_samples_y.reshape(-1,1)\n",
    "    train_samples = np.hstack((train_samples_x, train_samples_y)).tolist()\n",
    "\n",
    "    print(\"Train Count: \", len(train_samples), \", Holdout Count: \", len(holdout_samples))\n",
    "    random.shuffle(train_samples)\n",
    "    random.shuffle(holdout_samples)\n",
    "    print(\"Train Count: \", len(train_samples), \", Holdout Count: \", len(holdout_samples))\n",
    "\n",
    "    return train_samples, holdout_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "Full Count:  91564\n",
      "Orginal Grade_0:  18873\n",
      "Orginal Grade_1:  18462\n",
      "Orginal Grade_2:  12797\n",
      "Orginal Grade_3:  31434\n",
      "Orginal Grade_4:  9998\n",
      "Train Count Grade_0:  16985 , Holdout Count Grade_0:  1888\n",
      "Train Count Grade_1:  16615 , Holdout Count Grade_1:  1847\n",
      "Train Count Grade_2:  11517 , Holdout Count Grade_2:  1280\n",
      "Train Count Grade_3:  28290 , Holdout Count Grade_3:  3144\n",
      "Train Count Grade_4:  8998 , Holdout Count Grade_4:  1000\n",
      "Train Count:  82405 , Holdout Count:  9159\n",
      "Train Sample_X:  141450 , Train Sample_Y:  141450\n",
      "Train Count:  141450 , Holdout Count:  9159\n",
      "Train Count:  141450 , Holdout Count:  9159\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_files, holdout_files = get_train_holdout_files(train_percentage=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_keras",
   "language": "python",
   "name": "my_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
